{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Estimated Errors (Rs)  -> 0.474718, 0.238205, 0.316756, 0.451414, 0.341583, 0.578385\n",
      "Fold 1: Mse  -> 0.280376, 0.105979, 0.102862, 0.101084, 0.047191, 0.037181\n",
      "opt m = 2\n",
      "Fold 2: Estimated Errors (Rs)  -> 0.496962, 0.554809, 0.705598, 0.892777, 1.398401, 0.044841\n",
      "Fold 2: Mse  -> 0.293514, 0.246838, 0.229132, 0.199917, 0.193194, 0.002883\n",
      "opt m = 6\n",
      "Fold 3: Estimated Errors (Rs)  -> 0.292626, 0.350852, 0.433446, 0.628226, 0.912884, 0.340425\n",
      "Fold 3: Mse  -> 0.172830, 0.156096, 0.140755, 0.140677, 0.126118, 0.021884\n",
      "opt m = 1\n",
      "Fold 4: Estimated Errors (Rs)  -> 0.411378, 0.368631, 0.441462, 0.634569, 0.937692, 0.650529\n",
      "Fold 4: Mse  -> 0.242967, 0.164006, 0.143358, 0.142097, 0.129546, 0.041818\n",
      "opt m = 2\n",
      "Fold 5: Estimated Errors (Rs)  -> 0.237259, 0.284802, 0.294948, 0.373933, 0.338964, 0.505308\n",
      "Fold 5: Mse  -> 0.140129, 0.126710, 0.095780, 0.083734, 0.046829, 0.032483\n",
      "opt m = 1\n",
      "2.3181972769483083\n",
      "   fold  optimal m  Prediction accuracy(MSE)       NRMS\n",
      "0     0          2                  1.025454   9.298646\n",
      "1     1          6                  8.785885 -23.589363\n",
      "2     2          1                  0.242589   1.014061\n",
      "3     3          2                  0.574730  -1.829155\n",
      "4     4          1                  0.962329   1.096365\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 1: Estimated Errors (Rs)  -> 0.449026, 0.482011, 0.196566, 0.266883, 0.425140, 0.649809\n",
      "Fold 1: Mse  -> 0.265202, 0.214450, 0.063832, 0.059762, 0.058735, 0.041772\n",
      "opt m = 3\n",
      "Fold 2: Estimated Errors (Rs)  -> 0.477054, 0.531230, 0.259922, 0.276863, 0.385684, 0.823390\n",
      "Fold 2: Mse  -> 0.281756, 0.236348, 0.084406, 0.061997, 0.053284, 0.052930\n",
      "opt m = 3\n",
      "Fold 3: Estimated Errors (Rs)  -> 0.409798, 0.251318, 0.056455, 0.064301, 0.088883, 0.021628\n",
      "Fold 3: Mse  -> 0.242034, 0.111813, 0.018333, 0.014399, 0.012279, 0.001390\n",
      "opt m = 6\n",
      "Fold 4: Estimated Errors (Rs)  -> 0.178353, 0.230204, 0.304175, 0.229639, 0.027217, 0.017786\n",
      "Fold 4: Mse  -> 0.105338, 0.102419, 0.098776, 0.051423, 0.003760, 0.001143\n",
      "opt m = 6\n",
      "Fold 5: Estimated Errors (Rs)  -> 0.228989, 0.225905, 0.262240, 0.377378, 0.288550, 0.008736\n",
      "Fold 5: Mse  -> 0.135245, 0.100507, 0.085158, 0.084505, 0.039864, 0.000562\n",
      "opt m = 6\n",
      "1743358616.8537018\n",
      "   fold  optimal m  Prediction accuracy(MSE)          NRMS\n",
      "0     0          3                 26.901699     47.626815\n",
      "1     1          3                  8.694093    -23.465812\n",
      "2     2          6                  0.766090      1.802057\n",
      "3     3          6             309839.490014  -1343.034390\n",
      "4     4          6         8716483208.416613 104343.187494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def generate_data():\n",
    "    np.random.seed(33)\n",
    "    x = np.random.uniform(0, 1, 10)\n",
    "    x.sort()\n",
    "    noise = np.random.normal(0, np.sqrt(0.25), 10)\n",
    "    y = x**2 + 0.1 * x + noise\n",
    "    return x, y\n",
    "\n",
    "def trig_func(x, m):\n",
    "    Xtri = np.column_stack([np.cos(2 * np.pi * i * x) for i in range(1, m + 1)])\n",
    "    Xtri = np.column_stack([np.ones(x.shape), Xtri])\n",
    "    return Xtri\n",
    "\n",
    "def poly_func(x, m):\n",
    "    Xpoly = np.column_stack([x**i for i in range(m + 1)])\n",
    "    Xpoly = np.column_stack([np.ones(x.shape), Xpoly])\n",
    "    return Xpoly\n",
    "\n",
    "def schwarz_criterion(DoF, n, Remp):\n",
    "    p = DoF / n\n",
    "    return (1 + p * ((1-p) ** -1) * np.log(n)) * Remp\n",
    "\n",
    "def calculate_nrms(y_true, y_pred, normalization=\"mean\"):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    if normalization == \"range\":\n",
    "        scale = np.max(y_true) - np.min(y_true)\n",
    "    elif normalization == \"mean\":\n",
    "        scale = np.mean(y_true)\n",
    "    elif normalization == \"std\":\n",
    "        scale = np.std(y_true)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization method\")\n",
    "    nrms = rmse / scale\n",
    "    return nrms\n",
    "\n",
    "\n",
    "def train(x, y, func):\n",
    "    kf = KFold(n_splits=5)\n",
    "  \n",
    "    folds = range(0,5)\n",
    "    opt_ms = []\n",
    "    pred_accs = []\n",
    "    nrms = []\n",
    "\n",
    "    for j, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "        X_train, X_test = x[train_index], y[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        complexities = range(1, 7)\n",
    "\n",
    "        Est_r = []\n",
    "        emps = []\n",
    "\n",
    "        for m in complexities:\n",
    "            model = LinearRegression()\n",
    "            model.fit(func(X_train, m), y_train)\n",
    "            y_pred = model.predict(func(X_train, m))\n",
    "            emp =  np.mean((y_train - y_pred) ** 2)\n",
    "            emps.append(emp)\n",
    "            Est_r.append(schwarz_criterion(m+1, sample_size, emp))\n",
    "        \n",
    "        Est_r_formatted = ', '.join([f\"{value:.6f}\" for value in Est_r])\n",
    "        emps_formatted = ', '.join([f\"{value:.6f}\" for value in emps])\n",
    "        print(f\"Fold {j+1}: Estimated Errors (Rs)  -> {Est_r_formatted}\")\n",
    "        print(f\"Fold {j+1}: Mse  -> {emps_formatted}\")\n",
    "    \n",
    "        opt_m_index = np.argmin(Est_r)\n",
    "        opt_m = opt_m_index + 1\n",
    "        print(f\"opt m = {opt_m}\")\n",
    "        opt_ms.append(opt_m)\n",
    "\n",
    "        opt_model = LinearRegression()\n",
    "        opt_model.fit(func(X_train, opt_m ), y_train)\n",
    "        y_pred_opt = opt_model.predict(func(X_test, opt_m))\n",
    "        mse = np.mean((y_test - y_pred_opt) ** 2)\n",
    "        nrm = calculate_nrms(y_test, y_pred_opt)\n",
    "        nrms.append(nrm)\n",
    "        pred_accs.append(mse)\n",
    "        # print(mse)\n",
    "        \n",
    "    pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "    results_df = pd.DataFrame({'fold': folds,\n",
    "                                'optimal m': opt_ms,\n",
    "                                'Prediction accuracy(MSE)': pred_accs,\n",
    "                                'NRMS': nrms})\n",
    "    print(np.mean(pred_accs))\n",
    "    \n",
    "    print(results_df)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    sample_size = 8\n",
    "\n",
    "    x, y = generate_data()\n",
    "    train(x, y, trig_func)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    train(x, y, poly_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw02env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
